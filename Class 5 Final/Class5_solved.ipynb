{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz6n5gTFq38H"
      },
      "source": [
        "# Dealing with Data Spring 2022 – Class 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKStz2feq38O"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8p1fJxhq38P"
      },
      "source": [
        "# Files and Printing\n",
        "\n",
        "Often you will need to read data from a file, or write the output of a Python script back to a file. \n",
        "\n",
        "We use the `open` function to open the file in the appropriate mode, which takes two arguments: \n",
        "\n",
        "1. the name of the file,\n",
        "2. and the mode. \n",
        "\n",
        "> `a_file = open(filename, mode)`\n",
        "\n",
        "The `mode` is a single letter string that specifies if you are going to be reading from a file, writing to a file, or appending to the end of an existing file. The modes are: \n",
        "\n",
        "+ `'r'` : open a file for reading\n",
        "+ `'w'` : open a file for writing (beware, this will overwrite any previously existing file) \n",
        "+ `'a'` : append (write to the end of a file) \n",
        "\n",
        "When reading a file, you usually want to iterate through the lines in that file using a `for loop`. Some other common methods for dealing with files are: \n",
        "\n",
        "+ `file.read()` : read the entire contents of a file into a string\n",
        "+ `file.write(some_string)` : writes to the file (note, this doesn't automatically include new lines) \n",
        "+ `file.close()` : close the open file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtBzRKFqq38Q"
      },
      "source": [
        "# Writing a file to disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydpwOnH3q38Q"
      },
      "outputs": [],
      "source": [
        "# create the file temp.txt, and get it ready for writing\n",
        "\n",
        "f = open(\"temp.txt\", \"w\") # \"w\" meaning we want to open it for writing\n",
        "f.write(\"This is my first file! The end!\\n\") # writing our text to our file\n",
        "f.write(\"Oh wait, I wanted to say something else.\") # writing some more text to our file\n",
        "f.close() # closing out the file as a best practices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GB-tkRgq38R"
      },
      "outputs": [],
      "source": [
        "# the command below is one of the IPython \"magics\" - commands within the notebook unrelated to python\n",
        "# %magic shows you the list of basic commands and %lsmagic shows you all the super commands\n",
        "\n",
        "# for more info, check out https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/\n",
        "\n",
        "%less temp.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SIQNJm6q38R"
      },
      "source": [
        "# Reading a file from disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXzblL4Dq38S"
      },
      "outputs": [],
      "source": [
        "# open the file for reading\n",
        "\n",
        "f = open(\"temp.txt\", \"r\") # opening the file with read permissions\n",
        "content = f.read() # read the full content of the file in memory, as a big string\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgUPWtxaq38S"
      },
      "outputs": [],
      "source": [
        "content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ajJ9AXgq38S"
      },
      "source": [
        "Once we read the file, we have the lines in a big string. Let's process that big string a little bit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh69hvhHq38S"
      },
      "outputs": [],
      "source": [
        "# read the file in the cell above and split the content of the file using the newline character '\\n'\n",
        "\n",
        "lines = content.split(\"\\n\") # let's split on the new line return; remember the output is going to be a list\n",
        "\n",
        "for line in lines: # iterate through the line variable (it is a list of strings) and then print the length of each line\n",
        "    print(line, \" ===> \", len(line))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUOKgUdDq38T"
      },
      "outputs": [],
      "source": [
        "# create a new file numbers.txt and write the numbers from 0 to 24 there\n",
        "\n",
        "f = open(\"numbers.txt\", \"w\")\n",
        "\n",
        "for num in range(25): \n",
        "    f.write(str(num)+'\\n') # write each number followed by a new line\n",
        "    \n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPe8FUADq38T"
      },
      "outputs": [],
      "source": [
        "%less numbers.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQnKR0Clq38T"
      },
      "outputs": [],
      "source": [
        "f = open(\"numbers.txt\", \"r\") # now open the file for reading\n",
        "\n",
        "content = f.read() # and read the full content of the file in memory, as a big string\n",
        "\n",
        "f.close()\n",
        "\n",
        "content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VsFy5xXq38T"
      },
      "outputs": [],
      "source": [
        "# here we convert the strings into integers\n",
        "\n",
        "lines = content.split(\"\\n\")\n",
        "\n",
        "for line in lines: \n",
        "    print(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFI9raFIq38T"
      },
      "outputs": [],
      "source": [
        "# Let's clean up\n",
        "\n",
        "# windows\n",
        "#!del temp.txt\n",
        "#!del numbers.txt\n",
        "\n",
        "# macOS\n",
        "!rm temp.txt # remove temp.txr file\n",
        "!rm numbers.txt #remove numbers.txt file"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "^Please note that in Colab it takes a minute or so for the !rm changes to come into effect."
      ],
      "metadata": {
        "id": "_u6miFzx4XPM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy06siIeGRZM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭕ **QUESTIONS?**"
      ],
      "metadata": {
        "id": "4GZojYnLW3O4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv9DsLKxUy5i"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFS_sVmPq38U"
      },
      "source": [
        "# Python `os` standard library\n",
        "Another addition to our file handling toolkit is the `os` library which provides ways to move files, make directories, and gather data about the file system. Like other standard libraries, we need to import it to use it via `import os`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LlzYGXtq38U"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# let's get info about our current working directory - the folder our Python applications are working in\n",
        "os.getcwd() # cwd = \"current working directory\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "^ Remember, all of the above is applying to our Colab environment. If you open up your computer's terminal or command line and type ```pwd``` (print working directory) you will most likely get a different response."
      ],
      "metadata": {
        "id": "0goJc63Z4wKD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOylkvGZq38U"
      },
      "outputs": [],
      "source": [
        "# next, let's list everything in the directory\n",
        "\n",
        "os.listdir() # list directory contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsLxv8Mmq38V"
      },
      "outputs": [],
      "source": [
        "# ... and find out the \"separate\" used in constructing file paths\n",
        "# every operating system is different, and this value enables your python to be cross-platform \n",
        "\n",
        "os.path.sep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mchvQhMRq38V"
      },
      "outputs": [],
      "source": [
        "# ... now we can create our own paths for new files - important for creating a \"clean\" version of source data\n",
        "\n",
        "dir_list = os.getcwd().split(os.path.sep)\n",
        "print(dir_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_pvJnJpq38V"
      },
      "outputs": [],
      "source": [
        "# ... now let's create an output file in a new sub-folder called Class 5 - tmp\n",
        "\n",
        "# first - append the new folder name and create a file path string using os.path.sep and the string.join() method\n",
        "\n",
        "dir_list.append(\"Class5_tmp\") # add a new suffix to our list\n",
        "dir_string = os.path.sep.join(dir_list) # and join everything in our directory list with the '/' speartor\n",
        "\n",
        "# second - create the directory using the file path\n",
        "\n",
        "os.mkdir(dir_string)\n",
        "\n",
        "# third - add the file name \"tmp2.txt\" to the path\n",
        "\n",
        "dir_list.append(\"tmp2.txt\")\n",
        "dir_string = os.path.sep.join(dir_list)\n",
        "\n",
        "print(dir_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OZR4Zliq38W"
      },
      "outputs": [],
      "source": [
        "# we can now open the file for writing using the absolute path \n",
        "\n",
        "file_handle = open(dir_string,\"w\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2Upafg-q38W"
      },
      "outputs": [],
      "source": [
        "file_handle.write(\"test file\\nsecond line\\n\")\n",
        "file_handle.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%less /content/Class5_tmp/tmp2.txt"
      ],
      "metadata": {
        "id": "NjoxvQKww6cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_qW5Lu4q38W"
      },
      "outputs": [],
      "source": [
        "# clean up \n",
        "\n",
        "!rm Class5_tmp/tmp2.txt\n",
        "!rmdir Class5_tmp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfV6HcaOwZNI"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭕ **QUESTIONS?**"
      ],
      "metadata": {
        "id": "RxbYfgUzwZNQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wteUtTXOwZNQ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1-TP6qnq38W"
      },
      "source": [
        "# **Putting our Python to work: Exploring and Cleaning the Census Data file**\n",
        "\n",
        "Our approach will be as follows:\n",
        "* Inspect the data thoroughly to understand its benefits and risks for processing, and what information lies within\n",
        "* Clean/fix the data to remove any issues that would prevent it from working with SQL, such as weird characters, too many columns, missing data, splitting values into multiple rows, or combining multiple values into a single row\n",
        "* Structure the data found in the file as a Python native structure so we can manipulate and prepare it for use in SQL\n",
        "* Migrate our approach to a dedicated Python file\n",
        "\n",
        "We'll use: file read/write, loops, nested structures and UDFs to do all of this. (Some will be homework.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsjhNbbFq38X"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iNswvX_q38X"
      },
      "source": [
        "## **1) Inspect our Data**\n",
        "\n",
        "Upon visual inspection:\n",
        "* there are 350+ columns\n",
        "* there are zipcodes for just NYC \n",
        "* there are a mix of letter and numbers for values\n",
        "* we have both percent and numbers values\n",
        "* it appears to be comma-separated\n",
        "* there are two column header lines: one with codes, and another with human-readable labels\n",
        "\n",
        "Next - we inspect with Python in two ways: first we'll look at the raw file as a string, then we'll probe whether the comma-separation is fail safe or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtY20TUNq38X"
      },
      "outputs": [],
      "source": [
        "# REVIEWING DATA AS A STRING\n",
        "\n",
        "import os\n",
        "os.getcwd()\n",
        "\n",
        "import shutil # will allow us to do some more work with copying, removing files in our Python os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pulkvrwyq38X"
      },
      "source": [
        "To work in Google Colab, we must manually upload our CSV into the environment..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y-Q3iE3q38X"
      },
      "outputs": [],
      "source": [
        "# find the location of the raw_census_2010.csv file you downloaded, copy, and open it for reading into a variable\n",
        "\n",
        "shutil.copyfile('/content/raw_census_2010.csv','/content/raw_census_2010_copy.csv')\n",
        "\n",
        "file_handle = open('/content/raw_census_2010_copy.csv',\"r\")\n",
        "\n",
        "census_data = file_handle.read()\n",
        "file_handle.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qxSvboZq38Y"
      },
      "outputs": [],
      "source": [
        "# print the first 500 characters of the census file\n",
        "\n",
        "census_data[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUXN8d4Tq38Y"
      },
      "outputs": [],
      "source": [
        "# and the last 500 characters\n",
        "census_data[-500:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBcdJ4ANq38Y"
      },
      "source": [
        "# **Review Comma-Based Separability**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B39GABI4q38Y"
      },
      "source": [
        "In the first 500 characters, we see that the census has \"code labels\" for each column, none of which have funky characters that could trip us up with comma separation. \n",
        "\n",
        "We need to work with just that first line, though, so we'll use readline (which reads one entire line from the file) on the file handle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkNlGFxRq38Y"
      },
      "outputs": [],
      "source": [
        "file_handle = open('/content/raw_census_2010_copy.csv',\"r\")\n",
        "census_first_line = file_handle.readline()\n",
        "file_handle.close()\n",
        "census_first_line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3B98uM5q38Y"
      },
      "outputs": [],
      "source": [
        "# let's separate that first line into a list and see exactly how many columns we have\n",
        "\n",
        "header1_list = census_first_line.split(\",\")\n",
        "len(header1_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37KWx6hUq38Z"
      },
      "source": [
        "We knew it had 350+ and this is too many columns to effectively work with. \n",
        "\n",
        "Before we get to removing data, though, we need to put our data into a structure we can slice and dice. In other words, we need to transform our \"string\" data into a list of lists - a nested data structure where each row is a list, and within that list, each column is a list - a nested data structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVz_5ebqq38Z"
      },
      "source": [
        "For example: let's look at this simple 3x3 table:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxXP04gFq38Z"
      },
      "outputs": [],
      "source": [
        "example_list = [ \n",
        "    [\"a\",\"b\",\"c\"],\n",
        "    [123,456,789],\n",
        "    [987,654,321]\n",
        "    ]\n",
        "\n",
        "print(example_list[0])\n",
        "print(example_list[1])\n",
        "print(example_list[2])\n",
        "\n",
        "print(\"row 1, column 3 ==>\",example_list[0][2])\n",
        "print(\"row 2, column 2 ==>\",example_list[1][1])\n",
        "print(\"row 3, column 1 ==>\",example_list[2][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cf26acnq38Z"
      },
      "source": [
        "## **2) Cleaning Up Wonky Data**\n",
        "\n",
        "But before we can even create a nested structure - we need to be confident we can split the data correctly for every single line.\n",
        "\n",
        "Unfortunately, CSV data is known to be particularly tricky because sometimes data sources use commas in column labels but surround those column headers with \"\" because Excel will treat it right. \n",
        "\n",
        "Python won't be so forgiving so we need to test for \"\" in the data - we'll do this using a for loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SN8nX9wq38Z"
      },
      "outputs": [],
      "source": [
        "# using a for loop\n",
        "\n",
        "quote_count = 0\n",
        "\n",
        "for char in census_data:\n",
        "    if char == '\"':\n",
        "        quote_count += 1\n",
        "    else:\n",
        "        continue\n",
        "        \n",
        "print(quote_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLaG063nq38Z"
      },
      "source": [
        "Uh-oh! those quotes spell trouble so now we need to see where that first quote appears and if a comma appears after it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAUTQxojq38Z"
      },
      "outputs": [],
      "source": [
        "quote_pos = census_data.find('\"')\n",
        "comma_pos = census_data.find(\",\",quote_pos) # quote_pos is the starting index of that \"\n",
        "census_data[quote_pos - 10: comma_pos + 20] # let's take a look at ten characters before and 20 after to check it out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm5NbDHcq38Z"
      },
      "source": [
        "We suspect that those \"\"  in human-readable column headers of the second line of data are hiding \"...**,**...\" and will cause any nesting using comma-separation to create extra columns.\n",
        "\n",
        "Let's prove it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwqyyMTVq38a"
      },
      "outputs": [],
      "source": [
        "# we need to isolate the second line using \"find\": \n",
        "# the second line is between the first and second \\n\n",
        "\n",
        "first_nl = census_data.find(\"\\n\")\n",
        "second_nl = census_data.find(\"\\n\",first_nl+1)\n",
        "second_line = census_data[first_nl+1:second_nl]\n",
        "\n",
        "# split the second line using commas to see how many columns we get\n",
        "\n",
        "len(second_line.split(\",\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFsZsiK7q38a"
      },
      "source": [
        "Now that we've proven those will be a problem, we are going to use Python to clean those up via our own User Defined Function for this purpose, because it may appear in another data source, too.\n",
        "\n",
        "Before we create the UDF, let's describe what we want our function to do: \n",
        "\n",
        "1. it will accept a string input\n",
        "2. it will remove \" characters from the input\n",
        "3. when it finds a , between \"\" it will replace , characters in the input with a `-`. However, it will NOT change `,` otherwise since it is a CSV file.\n",
        "4. it will return a string output\n",
        "\n",
        "And, we will create a test_input and expected_output to test our UDF during development:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj5PP_Gmq38a"
      },
      "outputs": [],
      "source": [
        "def unquotable(input_string): # will remove those , within \"\" before changing , to \\t \n",
        "    \n",
        "    tmp_list = input_string.split('\"') # remove \" char by splitting the input string into a list using that char\n",
        "\n",
        "    # remove , char\n",
        "    for i in range(len(tmp_list)):\n",
        "        # skip items that start/end with commas as these aren't quoted items & we don't want to remove their commas \n",
        "        if (tmp_list[i][0] == \",\") or (tmp_list[i][-1] == \",\"):\n",
        "            continue\n",
        "        else: # replace , with - in quoted items\n",
        "            tmp_list[i] = tmp_list[i].replace(\",\",\"-\")\n",
        "\n",
        "    output = \",\".join(tmp_list) # rejoin items into a string\n",
        "\n",
        "    # get rid of any \",,\" and \",,,\" that could exist as it will add extra columns\n",
        "    output = output.replace(\",,,\",\",\")\n",
        "    output = output.replace(\",,\",\",\")\n",
        "    \n",
        "    return output # return string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtF8zGyeq38a"
      },
      "outputs": [],
      "source": [
        "# our test data\n",
        "\n",
        "test_input = 'something,\"test string: a,b,c\",other thing'\n",
        "exp_output = 'something,test string: a-b-c,other thing'\n",
        "\n",
        "test_output = unquotable(test_input) # our testing lines - run the UDF\n",
        "\n",
        "test_output == exp_output # compare UDF run to expected output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuFbF_c7q38a"
      },
      "outputs": [],
      "source": [
        "# now we try our second_line variable storing the problem row for cleaning \n",
        "# proof it works: no \" and len after CSV split = 375\n",
        "\n",
        "new_row = unquotable(second_line)\n",
        "\n",
        "print('\"' in new_row)\n",
        "print(len(new_row.split(\",\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riaQfpmaq38a"
      },
      "source": [
        "It works! Now, let's fix our original input data string, `census_data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpuaYEYsq38b"
      },
      "outputs": [],
      "source": [
        "clean_census_data = unquotable(census_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH-RvaJqq38b"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N7ya7Efq38b"
      },
      "source": [
        "## **3) Creating a Nested Structure**\n",
        "\n",
        "Now that we've cleaned up the wonkiness in the data, we can create our nested structure using a `for` loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp_e3TgMq38b"
      },
      "source": [
        "Let's start by reviewing our simple 3x3 table example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYbaRya3q38b"
      },
      "outputs": [],
      "source": [
        "example_list = [ \n",
        "    [\"a\",\"b\",\"c\"],\n",
        "    [123,456,789],\n",
        "    [987,654,321]\n",
        "    ]\n",
        "\n",
        "print(example_list[0])\n",
        "print(example_list[1])\n",
        "print(example_list[2])\n",
        "\n",
        "print(\"row 1, column 3 ==>\",example_list[0][2])\n",
        "print(\"row 2, column 2 ==>\",example_list[1][1])\n",
        "print(\"row 3, column 1 ==>\",example_list[2][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zdCVmxJq38b"
      },
      "source": [
        "In our example, the data is structured as:\n",
        "\n",
        "`list[row][column]`\n",
        "\n",
        "And we will use split commands to do the same for our data, this time creating another UDF.\n",
        "\n",
        "Again - as before - let's state what it will do and create test data:\n",
        "1. the UDF will take a data string as input\n",
        "* it will create a list where each line in the data, identified using `\\n`, is an item\n",
        "* for each item in the first list `list[row]`, it will create a list of columns, using comma-separation (`,`) to identify each item\n",
        "* it would be nice for the UDF user to specify what character separates rows and columns, separately\n",
        "* the UDF will return the nested data structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybZosbYhq38b"
      },
      "outputs": [],
      "source": [
        "# take a dataset string where each row is separated by input_row_delim and each column is separate by \n",
        "# input_col_delim to create a nested object of lists\n",
        "\n",
        "def nester(input_string,input_row_delim,input_col_delim):\n",
        "\n",
        "    row_list = input_string.split(input_row_delim) # create a list item for each row in the file using the row delimiter\n",
        "\n",
        "    nested_data = [] #output var\n",
        "\n",
        "    # created nested structure to store each column separately list of rows where each row is a list of columns)\n",
        "    for i in range(len(row_list)): \n",
        "        row = row_list[i]\n",
        "        col = row.split(input_col_delim)\n",
        "        nested_data.append(col)\n",
        "    \n",
        "    return nested_data # return the nested structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdWQpMpvq38b"
      },
      "outputs": [],
      "source": [
        "test_input = 'r1c1,r1c2,r1c3\\nr2c1,r2c2,r2c3\\nr3c1,r3c2,r3c3' # our test data\n",
        "exp_output = [\n",
        "    ['r1c1','r1c2','r1c3'],\n",
        "    ['r2c1','r2c2','r2c3'],\n",
        "    ['r3c1','r3c2','r3c3']\n",
        "    ]\n",
        "\n",
        "test_output = nester(test_input,'\\n',',') # our testing - run the UDF\n",
        "\n",
        "test_output == exp_output # compare UDF output to expected output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW-2pMrlq38c"
      },
      "source": [
        "Now we can create a nested structure of our census data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjF-wD7oq38c"
      },
      "outputs": [],
      "source": [
        "census_struc = nester(clean_census_data,'\\n',',') # structure our original string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6EBDHnpq38c"
      },
      "outputs": [],
      "source": [
        "print(census_struc[2]) # let's explore more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw6tgo7_q38c"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nYOEdbFq38c"
      },
      "source": [
        "## **4) Moving from Notebooks to \\*.py Files** \n",
        "\n",
        "But before you go to do that, we need to start moving the findings of our exploration into a dedicated python file for cleaning the Census data. \n",
        "\n",
        "We're making this migration because notebooks are great for exploring data, but as our files and project grow larger, it is simpler to run the Python files outside notebooks AND sometimes very large files can cause our notebooks to crash.\n",
        "\n",
        "Here's what that new Python file needs to do:\n",
        "\n",
        "1. read the census data file into a variable\n",
        "2. clean the data by removing the \"...,...\" problem using a UDF\n",
        "3. create a nested data structure\n",
        "4. remove unwanted columns\n",
        "5. create a new string from the nested structure\n",
        "6. write the file to disk\n",
        "\n",
        "We've already #1, #2, #3, and #6 together, so we'll isolate those below along with comments to do the other work before putting in its own file.\n",
        "\n",
        "And recall that our UDFs has to be put ahead of the main program to work because the Main Program needs to know what happens in those UDFs.\n",
        "\n",
        "Below is the exact code that will be put into its own file named `clean_census.py`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cED5Eujvq38c"
      },
      "source": [
        "```python\n",
        "################################################################\n",
        "##### UNQUOTABLE #############################################\n",
        "################################################################\n",
        "\n",
        "def unquotable(input_string): # removes pesky , within \"\" values before changing , to \\t in program\n",
        "    \n",
        "    # remove \" char by splitting the input string into a list using that char\n",
        "    tmp_list = input_string.split('\"')\n",
        " \n",
        "    # remove , char\n",
        "    for i in range(len(tmp_list)):\n",
        "        # skip items that start/end with commas as these aren't quoted items\n",
        "        if (tmp_list[i][0] == \",\") or (tmp_list[i][-1] == \",\"):\n",
        "            continue\n",
        "        # replace , with - in quoted items\n",
        "        else:\n",
        "            tmp_list[i] = tmp_list[i].replace(\",\",\"-\")\n",
        "\n",
        "    # rejoin items into a string\n",
        "    output = \",\".join(tmp_list)\n",
        "\n",
        "    # get rid of any \",,\" and \",,,\" as it will add extra columns\n",
        "    output = output.replace(\",,,\",\",\")\n",
        "    output = output.replace(\",,\",\",\")\n",
        "    \n",
        "    # return string\n",
        "    return output\n",
        "\n",
        "################################################################\n",
        "##### NESTER #############################################\n",
        "################################################################\n",
        "\n",
        "def nester(input_string,input_row_delim,input_col_delim): # take a dataset string where each row is separated by input_row_delim and each column is separate by input_col_delim to create a nested object of lists\n",
        "\n",
        "    # create a list item for each row in the file using the row delimiter\n",
        "    row_list = input_string.split(input_row_delim)\n",
        "\n",
        "    #output var\n",
        "    nested_data = []\n",
        "    \n",
        "    # created nested structure to store each column separately\n",
        "    # list of rows where each row is a list of columns)\n",
        "    for i in range(len(row_list)): \n",
        "        row = row_list[i]\n",
        "        col = row.split(input_col_delim)\n",
        "        nested_data.append(col)\n",
        "    \n",
        "    # return the nested structure\n",
        "    return nested_data\n",
        "\n",
        "\n",
        "################################################################\n",
        "##### MAIN PROGRAM #############################################\n",
        "################################################################\n",
        "\n",
        "# 1. read the census data file into a variable\n",
        "\n",
        "file_handle = open('raw_census_2010_copy.csv',\"r\")\n",
        "census_data = file_handle.read()\n",
        "file_handle.close()\n",
        "\n",
        "# 2. clean the data by removing the \"...,...\" problem using a UDF\n",
        "\n",
        "clean_census_data = unquotable(census_data)\n",
        "\n",
        "# 3. create a nested data structure with a UDF\n",
        "\n",
        "nested_census_data = nester(clean_census_data,\"\\n\",\",\")\n",
        "\n",
        "# 4. remove unwanted columns using a UDF\n",
        "\n",
        "# HOMEWORK\n",
        "\n",
        "# 5. create a new string from the nested structure using a UDF\n",
        "\n",
        "# HOMEWORK\n",
        "\n",
        "# 6. write the file to disk\n",
        "\n",
        "file_handle = open('raw_census_2010_copy.csv',\"r\")\n",
        "file_handle.write('final data var from step #5 goes here')\n",
        "file_handle.close()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7AL-D6pwbq3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭕ **QUESTIONS?**"
      ],
      "metadata": {
        "id": "GxZgKkhuwbq3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DpLBSOqwbq3"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Class5_solved.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}